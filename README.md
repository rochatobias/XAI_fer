# XAI para Reconhecimento de EmoÃ§Ãµes Faciais

Projeto de Explicabilidade (XAI) aplicada a modelos de deep learning para reconhecimento de emoÃ§Ãµes faciais, comparando Vision Transformers (ViT) e ConvNeXt (CNN).

## ğŸ“‹ Objetivo da Pesquisa

Investigar **onde** os modelos focam ao classificar emoÃ§Ãµes faciais, comparando:
- **ViT**: Mecanismos de atenÃ§Ã£o (attention maps)
- **CNN**: MÃ©todos baseados em gradiente (CAM)
- **AgnÃ³sticos**: LIME e SHAP (independentes de arquitetura)

## ğŸ§  DecisÃµes de ImplementaÃ§Ã£o

### Por que SeleÃ§Ã£o Estratificada de Heatmaps?

Processar milhares de imagens gera GBs de heatmaps. A **seleÃ§Ã£o estratificada** resolve isso:

```
7 classes Ã— 4 buckets Ã— 5 imagens = 140 heatmaps representativos
```

**Os 4 buckets capturam cenÃ¡rios de pesquisa importantes:**
| Bucket | DescriÃ§Ã£o | Interesse |
|--------|-----------|-----------|
| `correct_high` | Acertou com confianÃ§a alta | Caso ideal |
| `correct_low` | Acertou com confianÃ§a baixa | PossÃ­vel sorte |
| `wrong_high` | Errou com confianÃ§a alta | Caso problemÃ¡tico |
| `wrong_low` | Errou com confianÃ§a baixa | Imagem ambÃ­gua |

### Por que LIME/SHAP apenas nas imagens estratificadas?

- LIME/SHAP sÃ£o **~10-100x mais lentos** que mÃ©todos nativos
- Objetivo: **comparar heatmaps** lado a lado (nÃ£o calcular mÃ©tricas)
- Usar os mesmos 140 casos permite comparaÃ§Ã£o direta ViT vs CNN vs LIME/SHAP

### Por que LayerCAM ao invÃ©s de ScoreCAM?

ScoreCAM Ã© mais robusto mas **~10x mais lento** (inviÃ¡vel para datasets grandes). LayerCAM oferece bom equilÃ­brio velocidade/qualidade.

## ğŸš€ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone <https://github.com/rochatobias/XAI_fer.git>
cd IC-Projeto

# Crie e ative ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou: venv\Scripts\activate  # Windows

# Instale dependÃªncias
pip install -r XAI/requirements.txt
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Onde configurar os caminhos

Edite `XAI/scripts/config.py`:

```python
# ============ MODELOS - MODIFIQUE AQUI SE NECESSÃRIO ============
VIT_MODEL_DIR = str(PROJECT_ROOT / "Training" / "Models" / "ViT" / "best_checkpoint-45153")
CNN_MODEL_PATH = str(PROJECT_ROOT / "Training" / "Models" / "CNN" / "convnext_fold_5_best.pth")

# ============ DATASET - MODIFIQUE AQUI SE NECESSÃRIO ============
DATA_DIR = str(BASE_DIR / "data" / "aplicaÃ§Ã£oXAI")
```

### Requisitos dos Modelos

> âš ï¸ **IMPORTANTE**: Os modelos devem usar os mesmos parÃ¢metros de prÃ©-processamento do **ConvNeXt Base**:
> - Input size: 224Ã—224
> - Mean: (0.485, 0.456, 0.406)
> - Std: (0.229, 0.224, 0.225)

Se treinou modelos com parÃ¢metros diferentes, ajuste em `config.py`:
```python
IMG_SIZE = (224, 224)
MEAN = (0.485, 0.456, 0.406)
STD = (0.229, 0.224, 0.225)
```

### Estrutura esperada do dataset

```
XAI/data/aplicaÃ§Ã£oXAI/
â”œâ”€â”€ angry/
â”œâ”€â”€ disgust/
â”œâ”€â”€ fear/
â”œâ”€â”€ happy/
â”œâ”€â”€ neutral/
â”œâ”€â”€ sad/
â””â”€â”€ surprise/
```

### ParÃ¢metros principais

```python
N_SAMPLES = 1000         # Imagens para mÃ©tricas (ViT/CNN)
N_SAMPLES_AGNOSTIC = 50  # Limite para LIME/SHAP (dentro do estratificado)
```

## ğŸ¯ Como Executar

### Pipeline completo (ViT + CNN)
```bash
cd XAI/scripts
python main.py --n_samples 1000
```

### Com LIME/SHAP
```bash
python main.py --n_samples 1000 --agnostic
```

### Apenas ViT ou CNN
```bash
python main.py --models vit
python main.py --models cnn
```

### OpÃ§Ãµes disponÃ­veis
```bash
python main.py --help

--n_samples N       NÃºmero de imagens para mÃ©tricas
--models [vit/cnn]  Modelos a processar
--agnostic          Executar LIME/SHAP nas imagens estratificadas
--no-heatmaps       NÃ£o salvar visualizaÃ§Ãµes
--quiet             Modo silencioso
```

## ğŸ““ Notebook para Experimentos

Use `XAI/experiments.ipynb` para testes individuais:
- Carregar modelos
- Testar XAI em imagem Ãºnica
- Visualizar heatmaps inline
- Calcular mÃ©tricas manualmente

## ğŸ“Š MÃ©tricas Calculadas

### Fidelidade (quÃ£o bem o heatmap explica a decisÃ£o)
| MÃ©trica | DescriÃ§Ã£o |
|---------|-----------|
| **AOPC** | Queda de confianÃ§a ao remover regiÃµes importantes |
| **Insertion AUC** | ConfianÃ§a ao adicionar pixels importantes |
| **Deletion AUC** | ConfianÃ§a ao remover pixels importantes |

### Localidade (concentraÃ§Ã£o do heatmap)
| MÃ©trica | DescriÃ§Ã£o |
|---------|-----------|
| **Area@50/90** | % de Ã¡rea para capturar 50%/90% da atenÃ§Ã£o |
| **Gini** | Coeficiente de concentraÃ§Ã£o (maior = mais focado) |
| **Entropy** | DispersÃ£o (menor = mais focado) |

## ğŸ“ Estrutura do Projeto

```
IC-Projeto/
â”œâ”€â”€ Training/
â”‚   â””â”€â”€ Models/
â”‚       â”œâ”€â”€ ViT/              # Seu checkpoint ViT
â”‚       â””â”€â”€ CNN/              # Seu peso ConvNeXt
â”œâ”€â”€ XAI/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ aplicaÃ§Ã£oXAI/     # Dataset (7 pastas de emoÃ§Ãµes)
â”‚   â”œâ”€â”€ results/
â”‚   â”‚   â”œâ”€â”€ heatmaps/
â”‚   â”‚   â”‚   â”œâ”€â”€ vit/          # Heatmaps ViT
â”‚   â”‚   â”‚   â”œâ”€â”€ cnn/          # Heatmaps CNN
â”‚   â”‚   â”‚   â””â”€â”€ agnostic/     # Heatmaps LIME/SHAP
â”‚   â”‚   â”œâ”€â”€ summary/          # GrÃ¡ficos de resumo
â”‚   â”‚   â””â”€â”€ analysis/         # CSVs de anÃ¡lise
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ config.py         # âš™ï¸ ConfiguraÃ§Ãµes (modifique aqui)
â”‚   â”‚   â”œâ”€â”€ main.py           # Pipeline principal
â”‚   â”‚   â”œâ”€â”€ vit.py            # XAI para ViT
â”‚   â”‚   â”œâ”€â”€ cnn.py            # XAI para CNN
â”‚   â”‚   â”œâ”€â”€ agnostic.py       # LIME e SHAP
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ experiments.ipynb     # Notebook para testes
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ README.md
```

##  Resultados Gerados

| Arquivo | DescriÃ§Ã£o |
|---------|-----------|
| `metrics_combined.csv` | Todas as mÃ©tricas por imagem/mÃ©todo |
| `heatmap_selection.csv` | Imagens selecionadas e motivo |
| `heatmaps/vit/*.png` | VisualizaÃ§Ãµes ViT |
| `heatmaps/cnn/*.png` | VisualizaÃ§Ãµes CNN |
| `heatmaps/agnostic/*.png` | VisualizaÃ§Ãµes LIME/SHAP |
| `summary/*.png` | GrÃ¡ficos comparativos |
| `analysis/*.csv` | EstatÃ­sticas por mÃ©todo/classe |

## ğŸ“¦ DependÃªncias

- PyTorch â‰¥ 2.0
- Transformers (HuggingFace)
- timm
- grad-cam
- lime, shap (para mÃ©todos agnÃ³sticos)

## ğŸ‘¤ Autor

Tobias Rocha