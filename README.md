# XAI para Reconhecimento de EmoÃ§Ãµes Faciais

Projeto de Explicabilidade (XAI) aplicada a modelos de deep learning para reconhecimento de emoÃ§Ãµes faciais, comparando Vision Transformers (ViT) e ConvNeXt (CNN).

## ğŸ“‹ Objetivo da Pesquisa

Investigar **onde** os modelos focam ao classificar emoÃ§Ãµes faciais, comparando:
- **ViT**: Mecanismos de atenÃ§Ã£o (attention maps)
- **CNN**: MÃ©todos baseados em gradiente (CAM)
- **AgnÃ³sticos**: LIME e SHAP (independentes de arquitetura)

## ğŸ§  DecisÃµes de ImplementaÃ§Ã£o

### Por que SeleÃ§Ã£o Estratificada de Heatmaps?

Processar milhares de imagens gera GBs de heatmaps. A **seleÃ§Ã£o estratificada** resolve isso:

```
7 classes Ã— 4 buckets Ã— 5 imagens = 140 heatmaps representativos
```

**Os 4 buckets capturam cenÃ¡rios de pesquisa importantes:**
| Bucket | DescriÃ§Ã£o | Interesse |
|--------|-----------|-----------|
| `correct_high` | Acertou com confianÃ§a alta | Caso ideal |
| `correct_low` | Acertou com confianÃ§a baixa | PossÃ­vel sorte |
| `wrong_high` | Errou com confianÃ§a alta | Caso problemÃ¡tico |
| `wrong_low` | Errou com confianÃ§a baixa | Imagem ambÃ­gua |

### Por que LIME/SHAP apenas nas imagens estratificadas?

- LIME/SHAP sÃ£o **~10-100x mais lentos** que mÃ©todos nativos
- Objetivo: **comparar heatmaps** lado a lado (nÃ£o calcular mÃ©tricas)
- Usar os mesmos 140 casos permite comparaÃ§Ã£o direta ViT vs CNN vs LIME/SHAP

### Por que LayerCAM ao invÃ©s de ScoreCAM?

ScoreCAM Ã© mais robusto mas **~10x mais lento** (inviÃ¡vel para datasets grandes). LayerCAM oferece bom equilÃ­brio velocidade/qualidade.

## ğŸš€ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone <https://github.com/rochatobias/XAI_fer.git>
cd IC-Projeto

# Crie e ative ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou: venv\Scripts\activate  # Windows

# Instale dependÃªncias
pip install -r XAI/requirements.txt
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Onde configurar os caminhos

Edite `XAI/scripts/config.py`:

```python
# ============ MODELOS - MODIFIQUE AQUI SE NECESSÃRIO ============
VIT_MODEL_DIR = str(PROJECT_ROOT / "Training" / "Models" / "ViT" / "best_checkpoint-45153")
CNN_MODEL_PATH = str(PROJECT_ROOT / "Training" / "Models" / "CNN" / "convnext_fold_5_best.pth")

# ============ DATASET - MODIFIQUE AQUI SE NECESSÃRIO ============
DATA_DIR = str(BASE_DIR / "data" / "aplicaÃ§Ã£oXAI")
```

### Requisitos dos Modelos

> âš ï¸ **IMPORTANTE**: Os modelos devem usar os mesmos parÃ¢metros de prÃ©-processamento do **ConvNeXt Base**:
> - Input size: 224Ã—224
> - Mean: (0.485, 0.456, 0.406)
> - Std: (0.229, 0.224, 0.225)

Se treinou modelos com parÃ¢metros diferentes, ajuste em `config.py`:
```python
IMG_SIZE = (224, 224)
MEAN = (0.485, 0.456, 0.406)
STD = (0.229, 0.224, 0.225)
```

### Estrutura esperada do dataset

```
XAI/data/aplicaÃ§Ã£oXAI/
â”œâ”€â”€ angry/
â”œâ”€â”€ disgust/
â”œâ”€â”€ fear/
â”œâ”€â”€ happy/
â”œâ”€â”€ neutral/
â”œâ”€â”€ sad/
â””â”€â”€ surprise/
```

### ParÃ¢metros principais

```python
N_SAMPLES = 1000         # Imagens para mÃ©tricas (ViT/CNN)
N_SAMPLES_AGNOSTIC = 50  # Limite para LIME/SHAP (dentro do estratificado)
```

## ğŸ¯ Como Executar

### Menu Interativo (Recomendado)

Execute sem argumentos para abrir o menu:
```bash
cd XAI/scripts
python main.py
```

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         XAI ANALYSIS - MENU PRINCIPAL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  [1] Pipeline Completo (ViT + CNN)
  [2] Pipeline Apenas ViT
  [3] Pipeline Apenas CNN
  [4] Executar LIME/SHAP (imagens estratificadas)
  [5] Regenerar GrÃ¡ficos (usa CSV existente)
  [6] Regenerar CSVs de AnÃ¡lise
  [0] Sair
```

O menu solicita interativamente a quantidade de imagens e outras opÃ§Ãµes.

---

### Via Linha de Comando (Flags)

Para automaÃ§Ã£o ou scripts, use as flags:

#### ExecuÃ§Ã£o do Pipeline

```bash
# Pipeline completo (ViT + CNN) com 1000 imagens
python main.py --n_samples 1000

# Apenas ViT
python main.py --models vit --n_samples 500

# Apenas CNN
python main.py --models cnn --n_samples 500

# Com LIME/SHAP (10 imagens do estratificado)
python main.py --n_samples 1000 --agnostic --n_agnostic 10
```

#### Regenerar Outputs (sem reprocessar)

```bash
# Regenerar apenas grÃ¡ficos
python main.py --plots-only

# Regenerar apenas CSVs de anÃ¡lise
python main.py --analysis-only

# Executar apenas LIME/SHAP (usa CSV existente)
python main.py --agnostic-only
```

#### Flags de Controle

| Flag | Alias | DescriÃ§Ã£o |
|------|-------|-----------|
| `--n_samples N` | `-n` | NÃºmero de imagens para anÃ¡lise |
| `--n_agnostic N` | | NÃºmero de imagens para LIME/SHAP |
| `--models [vit/cnn]` | `-m` | Modelos a processar |
| `--agnostic` | `-a` | Executar LIME/SHAP nas imagens estratificadas |
| `--agnostic-only` | | Apenas LIME/SHAP (usa CSV existente) |
| `--plots-only` | | Regenerar apenas grÃ¡ficos |
| `--analysis-only` | | Regenerar apenas CSVs de anÃ¡lise |
| `--no-heatmaps` | | NÃ£o salvar visualizaÃ§Ãµes |
| `--no-plots` | | NÃ£o gerar grÃ¡ficos de resumo |
| `--no-analysis` | | NÃ£o gerar CSVs de anÃ¡lise |
| `--quiet` | `-q` | Modo silencioso |

#### Exemplos Combinados

```bash
# Pipeline rÃ¡pido para teste (10 imagens, sÃ³ ViT, sem plots)
python main.py -n 10 -m vit --no-plots --no-analysis

# Pipeline completo com LIME/SHAP customizado
python main.py --n_samples 5000 --agnostic --n_agnostic 50

# Modo silencioso para scripts
python main.py --n_samples 1000 --quiet
```

---


## ğŸ“Š MÃ©tricas Calculadas

### Fidelidade (quÃ£o bem o heatmap explica a decisÃ£o)
| MÃ©trica | DescriÃ§Ã£o |
|---------|-----------|
| **AOPC** | Queda de confianÃ§a ao remover regiÃµes importantes |
| **Insertion AUC** | ConfianÃ§a ao adicionar pixels importantes |
| **Deletion AUC** | ConfianÃ§a ao remover pixels importantes |

### Localidade (concentraÃ§Ã£o do heatmap)
| MÃ©trica | DescriÃ§Ã£o |
|---------|-----------|
| **Area@50/90** | % de Ã¡rea para capturar 50%/90% da atenÃ§Ã£o |
| **Gini** | Coeficiente de concentraÃ§Ã£o (maior = mais focado) |
| **Entropy** | DispersÃ£o (menor = mais focado) |

## ğŸ“ Estrutura do Projeto

```
IC-Projeto/
â”œâ”€â”€ Training/
â”‚   â””â”€â”€ Models/
â”‚       â”œâ”€â”€ ViT/              # Seu checkpoint ViT
â”‚       â””â”€â”€ CNN/              # Seu peso ConvNeXt
â”œâ”€â”€ XAI/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ aplicaÃ§Ã£oXAI/     # Dataset (7 pastas de emoÃ§Ãµes)
â”‚   â”œâ”€â”€ results/
â”‚   â”‚   â”œâ”€â”€ heatmaps/
â”‚   â”‚   â”‚   â”œâ”€â”€ vit/          # Heatmaps ViT
â”‚   â”‚   â”‚   â”œâ”€â”€ cnn/          # Heatmaps CNN
â”‚   â”‚   â”‚   â””â”€â”€ agnostic/     # Heatmaps LIME/SHAP
â”‚   â”‚   â”œâ”€â”€ summary/          # GrÃ¡ficos de resumo
â”‚   â”‚   â””â”€â”€ analysis/         # CSVs de anÃ¡lise
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ config.py         # âš™ï¸ ConfiguraÃ§Ãµes (modifique aqui)
â”‚   â”‚   â”œâ”€â”€ main.py           # Pipeline principal
â”‚   â”‚   â”œâ”€â”€ vit.py            # XAI para ViT
â”‚   â”‚   â”œâ”€â”€ cnn.py            # XAI para CNN
â”‚   â”‚   â”œâ”€â”€ agnostic.py       # LIME e SHAP
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ experiments.ipynb     # Notebook para testes
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ README.md
```

##  Resultados Gerados

| Arquivo | DescriÃ§Ã£o |
|---------|-----------|
| `metrics_combined.csv` | Todas as mÃ©tricas por imagem/mÃ©todo |
| `heatmap_selection.csv` | Imagens selecionadas e motivo |
| `heatmaps/vit/*.png` | VisualizaÃ§Ãµes ViT |
| `heatmaps/cnn/*.png` | VisualizaÃ§Ãµes CNN |
| `heatmaps/agnostic/*.png` | VisualizaÃ§Ãµes LIME/SHAP |
| `summary/*.png` | GrÃ¡ficos comparativos |
| `analysis/*.csv` | EstatÃ­sticas por mÃ©todo/classe |

## ğŸ“¦ DependÃªncias

- PyTorch â‰¥ 2.0
- Transformers (HuggingFace)
- timm
- grad-cam
- lime, shap (para mÃ©todos agnÃ³sticos)

## ğŸ‘¤ Autor

Tobias Rocha